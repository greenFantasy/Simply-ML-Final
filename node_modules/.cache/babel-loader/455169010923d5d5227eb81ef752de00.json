{"ast":null,"code":"import { isGenerator, isGraticuleGenerator, isInlineData, isNamedData, isSequenceGenerator, isUrlData, MAIN, RAW } from '../../data';\nimport * as log from '../../log';\nimport { isAggregate, isBin, isCalculate, isDensity, isFilter, isFlatten, isFold, isImpute, isJoinAggregate, isLoess, isLookup, isPivot, isQuantile, isRegression, isSample, isStack, isTimeUnit, isWindow } from '../../transform';\nimport { deepEqual, mergeDeep } from '../../util';\nimport { isFacetModel, isLayerModel, isUnitModel } from '../model';\nimport { requiresSelectionId } from '../selection';\nimport { AggregateNode } from './aggregate';\nimport { BinNode } from './bin';\nimport { CalculateNode } from './calculate';\nimport { OutputNode } from './dataflow';\nimport { DensityTransformNode } from './density';\nimport { FacetNode } from './facet';\nimport { FilterNode } from './filter';\nimport { FilterInvalidNode } from './filterinvalid';\nimport { FlattenTransformNode } from './flatten';\nimport { FoldTransformNode } from './fold';\nimport { getImplicitFromEncoding, getImplicitFromFilterTransform, getImplicitFromSelection, ParseNode } from './formatparse';\nimport { GeoJSONNode } from './geojson';\nimport { GeoPointNode } from './geopoint';\nimport { GraticuleNode } from './graticule';\nimport { IdentifierNode } from './identifier';\nimport { ImputeNode } from './impute';\nimport { AncestorParse } from './index';\nimport { JoinAggregateTransformNode } from './joinaggregate';\nimport { makeJoinAggregateFromFacet } from './joinaggregatefacet';\nimport { LoessTransformNode } from './loess';\nimport { LookupNode } from './lookup';\nimport { PivotTransformNode } from './pivot';\nimport { QuantileTransformNode } from './quantile';\nimport { RegressionTransformNode } from './regression';\nimport { SampleTransformNode } from './sample';\nimport { SequenceNode } from './sequence';\nimport { SourceNode } from './source';\nimport { StackNode } from './stack';\nimport { TimeUnitNode } from './timeunit';\nimport { WindowTransformNode } from './window';\nexport function findSource(data, sources) {\n  for (const other of sources) {\n    const otherData = other.data; // if both datasets have a name defined, we cannot merge\n\n    if (data.name && other.hasName() && data.name !== other.dataName) {\n      continue;\n    } // feature and mesh are mutually exclusive\n\n\n    if (data['format'] && data['format'].mesh && otherData.format && otherData.format.feature) {\n      continue;\n    }\n\n    if (isInlineData(data) && isInlineData(otherData)) {\n      if (deepEqual(data.values, otherData.values)) {\n        return other;\n      }\n    } else if (isUrlData(data) && isUrlData(otherData)) {\n      if (data.url === otherData.url) {\n        return other;\n      }\n    } else if (isNamedData(data)) {\n      if (data.name === other.dataName) {\n        return other;\n      }\n    }\n  }\n\n  return null;\n}\n\nfunction parseRoot(model, sources) {\n  if (model.data !== undefined || !model.parent) {\n    // if the model defines a data source or is the root, create a source node\n    if (model.data === null) {\n      // data: null means we should ignore the parent's data so we just create a new data source\n      const source = new SourceNode([]);\n      sources.push(source);\n      return source;\n    }\n\n    const existingSource = findSource(model.data, sources);\n\n    if (existingSource) {\n      if (!isGenerator(model.data)) {\n        existingSource.data.format = mergeDeep({}, model.data.format, existingSource.data.format);\n      } // if the new source has a name but the existing one does not, we can set it\n\n\n      if (!existingSource.hasName() && model.data.name) {\n        existingSource.dataName = model.data.name;\n      }\n\n      return existingSource;\n    } else {\n      const source = new SourceNode(model.data);\n      sources.push(source);\n      return source;\n    }\n  } else {\n    // If we don't have a source defined (overriding parent's data), use the parent's facet root or main.\n    return model.parent.component.data.facetRoot ? model.parent.component.data.facetRoot : model.parent.component.data.main;\n  }\n}\n/**\n * Parses a transform array into a chain of connected dataflow nodes.\n */\n\n\nexport function parseTransformArray(head, model, ancestorParse) {\n  let lookupCounter = 0;\n\n  for (const t of model.transforms) {\n    let derivedType = undefined;\n    let transformNode;\n\n    if (isCalculate(t)) {\n      transformNode = head = new CalculateNode(head, t);\n      derivedType = 'derived';\n    } else if (isFilter(t)) {\n      const implicit = getImplicitFromFilterTransform(t);\n      transformNode = head = ParseNode.makeWithAncestors(head, {}, implicit, ancestorParse) || head;\n      head = new FilterNode(head, model, t.filter);\n    } else if (isBin(t)) {\n      transformNode = head = BinNode.makeFromTransform(head, t, model);\n      derivedType = 'number';\n    } else if (isTimeUnit(t)) {\n      derivedType = 'date';\n      const parsedAs = ancestorParse.getWithExplicit(t.field); // Create parse node because the input to time unit is always date.\n\n      if (parsedAs.value === undefined) {\n        head = new ParseNode(head, {\n          [t.field]: derivedType\n        });\n        ancestorParse.set(t.field, derivedType, false);\n      }\n\n      transformNode = head = TimeUnitNode.makeFromTransform(head, t);\n    } else if (isAggregate(t)) {\n      transformNode = head = AggregateNode.makeFromTransform(head, t);\n      derivedType = 'number';\n\n      if (requiresSelectionId(model)) {\n        head = new IdentifierNode(head);\n      }\n    } else if (isLookup(t)) {\n      transformNode = head = LookupNode.make(head, model, t, lookupCounter++);\n      derivedType = 'derived';\n    } else if (isWindow(t)) {\n      transformNode = head = new WindowTransformNode(head, t);\n      derivedType = 'number';\n    } else if (isJoinAggregate(t)) {\n      transformNode = head = new JoinAggregateTransformNode(head, t);\n      derivedType = 'number';\n    } else if (isStack(t)) {\n      transformNode = head = StackNode.makeFromTransform(head, t);\n      derivedType = 'derived';\n    } else if (isFold(t)) {\n      transformNode = head = new FoldTransformNode(head, t);\n      derivedType = 'derived';\n    } else if (isFlatten(t)) {\n      transformNode = head = new FlattenTransformNode(head, t);\n      derivedType = 'derived';\n    } else if (isPivot(t)) {\n      transformNode = head = new PivotTransformNode(head, t);\n      derivedType = 'derived';\n    } else if (isSample(t)) {\n      head = new SampleTransformNode(head, t);\n    } else if (isImpute(t)) {\n      transformNode = head = ImputeNode.makeFromTransform(head, t);\n      derivedType = 'derived';\n    } else if (isDensity(t)) {\n      transformNode = head = new DensityTransformNode(head, t);\n      derivedType = 'derived';\n    } else if (isQuantile(t)) {\n      transformNode = head = new QuantileTransformNode(head, t);\n      derivedType = 'derived';\n    } else if (isRegression(t)) {\n      transformNode = head = new RegressionTransformNode(head, t);\n      derivedType = 'derived';\n    } else if (isLoess(t)) {\n      transformNode = head = new LoessTransformNode(head, t);\n      derivedType = 'derived';\n    } else {\n      log.warn(log.message.invalidTransformIgnored(t));\n      continue;\n    }\n\n    if (transformNode && derivedType !== undefined) {\n      for (const field of transformNode.producedFields() || []) {\n        ancestorParse.set(field, derivedType, false);\n      }\n    }\n  }\n\n  return head;\n}\n/*\nDescription of the dataflow (http://asciiflow.com/):\n     +--------+\n     | Source |\n     +---+----+\n         |\n         v\n     FormatParse\n     (explicit)\n         |\n         v\n     Transforms\n(Filter, Calculate, Binning, TimeUnit, Aggregate, Window, ...)\n         |\n         v\n     FormatParse\n     (implicit)\n         |\n         v\n Binning (in `encoding`)\n         |\n         v\n Timeunit (in `encoding`)\n         |\n         v\nFormula From Sort Array\n         |\n         v\n      +--+--+\n      | Raw |\n      +-----+\n         |\n         v\n  Aggregate (in `encoding`)\n         |\n         v\n  Stack (in `encoding`)\n         |\n         v\n  Invalid Filter\n         |\n         v\n   +----------+\n   |   Main   |\n   +----------+\n         |\n         v\n     +-------+\n     | Facet |----> \"column\", \"column-layout\", and \"row\"\n     +-------+\n         |\n         v\n  ...Child data...\n*/\n\nexport function parseData(model) {\n  let head = parseRoot(model, model.component.data.sources);\n  const _model$component$data = model.component.data,\n        outputNodes = _model$component$data.outputNodes,\n        outputNodeRefCounts = _model$component$data.outputNodeRefCounts;\n  const ancestorParse = model.parent ? model.parent.component.data.ancestorParse.clone() : new AncestorParse();\n  const data = model.data;\n\n  if (isGenerator(data)) {\n    // insert generator transform\n    if (isSequenceGenerator(data)) {\n      head = new SequenceNode(head, data.sequence);\n    } else if (isGraticuleGenerator(data)) {\n      head = new GraticuleNode(head, data.graticule);\n    } // no parsing necessary for generator\n\n\n    ancestorParse.parseNothing = true;\n  } else if (data && data.format && data.format.parse === null) {\n    // format.parse: null means disable parsing\n    ancestorParse.parseNothing = true;\n  }\n\n  head = ParseNode.makeExplicit(head, model, ancestorParse) || head; // Default discrete selections require an identifier transform to\n  // uniquely identify data points as the _id field is volatile. Add\n  // this transform at the head of our pipeline such that the identifier\n  // field is available for all subsequent datasets. Additional identifier\n  // transforms will be necessary when new tuples are constructed\n  // (e.g., post-aggregation).\n\n  if (requiresSelectionId(model) && // only add identifier to unit/layer models that do not have layer parents to avoid redundant identifier transforms\n  (isUnitModel(model) || isLayerModel(model)) && (!model.parent || !isLayerModel(model.parent))) {\n    head = new IdentifierNode(head);\n  } // HACK: This is equivalent for merging bin extent for union scale.\n  // FIXME(https://github.com/vega/vega-lite/issues/2270): Correctly merge extent / bin node for shared bin scale\n\n\n  const parentIsLayer = model.parent && isLayerModel(model.parent);\n\n  if (isUnitModel(model) || isFacetModel(model)) {\n    if (parentIsLayer) {\n      head = BinNode.makeFromEncoding(head, model) || head;\n    }\n  }\n\n  if (model.transforms.length > 0) {\n    head = parseTransformArray(head, model, ancestorParse);\n  } // create parse nodes for fields that need to be parsed (or flattened) implicitly\n\n\n  const implicitSelection = getImplicitFromSelection(model);\n  const implicitEncoding = getImplicitFromEncoding(model);\n  head = ParseNode.makeWithAncestors(head, {}, Object.assign(Object.assign({}, implicitSelection), implicitEncoding), ancestorParse) || head;\n\n  if (isUnitModel(model)) {\n    head = GeoJSONNode.parseAll(head, model);\n    head = GeoPointNode.parseAll(head, model);\n  }\n\n  if (isUnitModel(model) || isFacetModel(model)) {\n    if (!parentIsLayer) {\n      head = BinNode.makeFromEncoding(head, model) || head;\n    }\n\n    head = TimeUnitNode.makeFromEncoding(head, model) || head;\n    head = CalculateNode.parseAllForSortIndex(head, model);\n  } // add an output node pre aggregation\n\n\n  const rawName = model.getName(RAW);\n  const raw = new OutputNode(head, rawName, RAW, outputNodeRefCounts);\n  outputNodes[rawName] = raw;\n  head = raw;\n\n  if (isUnitModel(model)) {\n    const agg = AggregateNode.makeFromEncoding(head, model);\n\n    if (agg) {\n      head = agg;\n\n      if (requiresSelectionId(model)) {\n        head = new IdentifierNode(head);\n      }\n    }\n\n    head = ImputeNode.makeFromEncoding(head, model) || head;\n    head = StackNode.makeFromEncoding(head, model) || head;\n  }\n\n  if (isUnitModel(model)) {\n    head = FilterInvalidNode.make(head, model) || head;\n  } // output node for marks\n\n\n  const mainName = model.getName(MAIN);\n  const main = new OutputNode(head, mainName, MAIN, outputNodeRefCounts);\n  outputNodes[mainName] = main;\n  head = main; // add facet marker\n\n  let facetRoot = null;\n\n  if (isFacetModel(model)) {\n    const facetName = model.getName('facet'); // Derive new sort index field for facet's sort array\n\n    head = CalculateNode.parseAllForSortIndex(head, model); // Derive new aggregate for facet's sort field\n    // augment data source with new fields for crossed facet\n\n    head = makeJoinAggregateFromFacet(head, model.facet) || head;\n    facetRoot = new FacetNode(head, model, facetName, main.getSource());\n    outputNodes[facetName] = facetRoot;\n    head = facetRoot;\n  }\n\n  return Object.assign(Object.assign({}, model.component.data), {\n    outputNodes,\n    outputNodeRefCounts,\n    raw,\n    main,\n    facetRoot,\n    ancestorParse\n  });\n}","map":null,"metadata":{},"sourceType":"module"}